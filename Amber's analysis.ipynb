{
 "metadata": {
  "name": "",
  "signature": "sha256:a248420c32cecc454e405899fc85d70250f40045eb619e2aa2e94b05f21048cd"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import datetime as dt\n",
      "from scipy.stats import entropy\n",
      "\n",
      "# read in the framing and tone predictions\n",
      "data_dir = '/Users/dcard/Dropbox/CMU/ARK/compuframes/Analysis/Amber/data/'\n",
      "data_file = os.path.join(data_dir, 'corrected_for_stata.csv')\n",
      "data = pd.read_csv(data_file, header=0, index_col=0)\n",
      "\n",
      "# exclude irrelevant items and those from before 1980\n",
      "data = data.loc[(data['Irrelevant']==0) & (data['Year'] >= 1980)]\n",
      "print data.shape\n",
      "\n",
      "# convert year/month/day to date and quarter\n",
      "data['date'] = data.apply(lambda row: pd.Timestamp(dt.date(row['Year'], row['Month'], row['Day'])), axis=1)\n",
      "data['quarter'] = data.apply(lambda row: row['date'].quarter, axis=1)\n",
      "\n",
      "# compute the net tone\n",
      "data['tone'] = data['Pro'] - data['Anti']\n",
      "tone_cols = ['Pro', 'Neutral', 'Anti', 'tone']\n",
      "\n",
      "# sum up the confributions of each framing dimension\n",
      "frames = ['Capacity_and_resources',\n",
      "'Crime_and_punishment',\n",
      "'Cultural_identity',\n",
      "'Economic',\n",
      "'External_regulation',\n",
      "'Fairness_and_equality',\n",
      "'Health_and_safety',\n",
      "'Legality_jurisdiction',\n",
      "'Morality',\n",
      "'Policy_prescription',\n",
      "'Political',\n",
      "'Public_sentiment',\n",
      "'Quality_of_life',\n",
      "'Security_and_defense',\n",
      "'Other']\n",
      "\n",
      "data['all_frames_story'] = 0\n",
      "for f in frames:\n",
      "    data['all_frames_story'] += data[f]\n",
      "print data['all_frames_story'].describe()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(37478, 26)\n",
        "count    37478.000000\n",
        "mean         3.216142\n",
        "std          0.936989\n",
        "min          1.062568\n",
        "25%          2.564152\n",
        "50%          3.250936\n",
        "75%          3.937403\n",
        "max          9.535342\n",
        "Name: all_frames_story, dtype: float64"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "data['stories'] = 1\n",
      "    \n",
      "# group by year/quarter\n",
      "groups = data.groupby(['Year', 'quarter'])\n",
      "grouped = pd.DataFrame()\n",
      "\n",
      "grouped['stories'] = groups.aggregate(np.sum)['stories']\n",
      "for f in frames + tone_cols:\n",
      "    grouped[f] = groups.aggregate(np.mean)[f]\n",
      "\n",
      "# compute entropy (replication and then using scipy; they agree)\n",
      "grouped['all_frames'] = 0\n",
      "for f in frames:\n",
      "    grouped['all_frames'] += grouped[f]\n",
      "grouped['entropy.bruteforce'] = 0\n",
      "for f in frames:\n",
      "    grouped['p_' + f] = grouped[f] / grouped['all_frames']\n",
      "    grouped['lnp_' + f] = np.log(grouped['p_' + f])\n",
      "    grouped['p_lnp_' + f] = grouped['p_' + f] * grouped['lnp_' + f]\n",
      "    grouped['entropy.bruteforce'] -= grouped['p_lnp_' + f]\n",
      "\n",
      "grouped['entropy'] = grouped.apply(lambda row: entropy([row['p_' + f] for f in frames]), axis=1)\n",
      "\n",
      "print grouped['entropy'].describe()\n",
      "print grouped[['stories', 'entropy']].corr()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "count    132.000000\n",
        "mean       2.518983\n",
        "std        0.039395\n",
        "min        2.378412\n",
        "25%        2.502878\n",
        "50%        2.526837\n",
        "75%        2.542911\n",
        "max        2.594964\n",
        "Name: entropy, dtype: float64\n",
        "          stories   entropy\n",
        "stories  1.000000  0.232897\n",
        "entropy  0.232897  1.000000\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# compute the difference between quarters\n",
      "for f in frames:\n",
      "    grouped['chg_p_' + f] = grouped['p_' + f].diff(periods=1)\n",
      "\n",
      "# look for any big changes (there don't seem to be any)\n",
      "grouped['big_frame_change'] = np.array(np.max([grouped['chg_p_' + f] for f in frames]) >= 0.05, dtype=int)\n",
      "print np.max(grouped['big_frame_change'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# read in mood data\n",
      "#data_file = os.path.join(data_dir, 'month_smoothed.csv')\n",
      "#mood_by_month = pd.read_csv(data_file, header=0, index_col=0)\n",
      "data_file = os.path.join(data_dir, 'quarter_smoothed.csv')\n",
      "mood_by_quarter = pd.read_csv(data_file, header=0, index_col=0)\n",
      "\n",
      "# save the mood from the last quarter of 1979, since we're going to need it later\n",
      "mood_1979_4 = mood_by_quarter[mood_by_quarter['quarter'] == 4].loc[1979]['mood']\n",
      "\n",
      "# use the same date range as the framing data\n",
      "mood_by_quarter = mood_by_quarter.loc[(mood_by_quarter.index >= 1980) & (mood_by_quarter.index < 2013)]\n",
      "\n",
      "# sort via aggregation\n",
      "groups = mood_by_quarter.groupby([mood_by_quarter.index,  'quarter'])\n",
      "mood_grouped = pd.DataFrame()\n",
      "mood_grouped['mood'] = groups.aggregate(np.sum)['mood']\n",
      "\n",
      "a, _ = grouped.shape\n",
      "b, _ = mood_grouped.shape\n",
      "assert a == b\n",
      "\n",
      "# copy over the mood data\n",
      "grouped['mood'] = mood_grouped['mood']\n",
      "prev_mood = grouped['mood'].shift().as_matrix()\n",
      "prev_mood[0] = mood_1979_4\n",
      "grouped['prev_mood'] =  prev_mood\n",
      "print grouped.loc[1980,1]['prev_mood']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "42.263\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# add in salience and event variables\n",
      "grouped['dominance'] = - grouped['entropy']\n",
      "grouped['salient'] = grouped.apply(lambda row: int(row['stories'] >= 350), axis=1)\n",
      "grouped['event'] = 0\n",
      "# TODO: Figure out which quarters have events\n",
      "\n",
      "# add in interactions\n",
      "grouped['toneXstories'] = grouped['tone'] * grouped['stories']\n",
      "grouped['toneXsalient'] = grouped['tone'] * grouped['salient']\n",
      "grouped['toneXentropy'] = grouped['tone'] * grouped['entropy']\n",
      "grouped['toneXdominance'] = grouped['tone'] * grouped['dominance']\n",
      "grouped['toneXevent'] = grouped['tone'] * grouped['event']\n",
      "print grouped['salient'].describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "count    132.000000\n",
        "mean       0.363636\n",
        "std        0.482878\n",
        "min        0.000000\n",
        "25%        0.000000\n",
        "50%        0.000000\n",
        "75%        1.000000\n",
        "max        1.000000\n",
        "Name: salient, dtype: float64\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# run correlations\n",
      "print grouped[['mood', 'tone', 'stories', 'salient', 'entropy', 'dominance', 'event']].corr()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "               mood      tone   stories   salient   entropy  dominance  event\n",
        "mood       1.000000  0.336039  0.320113  0.334181 -0.136536   0.136536    NaN\n",
        "tone       0.336039  1.000000  0.017430 -0.025695  0.260641  -0.260641    NaN\n",
        "stories    0.320113  0.017430  1.000000  0.736564  0.232897  -0.232897    NaN\n",
        "salient    0.334181 -0.025695  0.736564  1.000000  0.149917  -0.149917    NaN\n",
        "entropy   -0.136536  0.260641  0.232897  0.149917  1.000000  -1.000000    NaN\n",
        "dominance  0.136536 -0.260641 -0.232897 -0.149917 -1.000000   1.000000    NaN\n",
        "event           NaN       NaN       NaN       NaN       NaN        NaN    NaN\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# run the first of the regressions using pandas\n",
      "pd.ols(y=grouped['mood'], x=grouped[['prev_mood', 'tone', 'stories', 'toneXstories', 'entropy', 'toneXentropy']])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "\n",
        "-------------------------Summary of Regression Analysis-------------------------\n",
        "\n",
        "Formula: Y ~ <prev_mood> + <tone> + <stories> + <toneXstories> + <entropy>\n",
        "             + <toneXentropy> + <intercept>\n",
        "\n",
        "Number of Observations:         132\n",
        "Number of Degrees of Freedom:   7\n",
        "\n",
        "R-squared:         0.7692\n",
        "Adj R-squared:     0.7581\n",
        "\n",
        "Rmse:              3.7761\n",
        "\n",
        "F-stat (6, 125):    69.4157, p-value:     0.0000\n",
        "\n",
        "Degrees of Freedom: model 6, resid 125\n",
        "\n",
        "-----------------------Summary of Estimated Coefficients------------------------\n",
        "      Variable       Coef    Std Err     t-stat    p-value    CI 2.5%   CI 97.5%\n",
        "--------------------------------------------------------------------------------\n",
        "     prev_mood     0.8182     0.0530      15.45     0.0000     0.7144     0.9220\n",
        "          tone   293.3753   120.1969       2.44     0.0161    57.7893   528.9612\n",
        "       stories    -0.0010     0.0030      -0.33     0.7450    -0.0070     0.0050\n",
        "  toneXstories     0.0306     0.0144       2.13     0.0350     0.0025     0.0588\n",
        "       entropy    -6.9941    11.7789      -0.59     0.5537   -30.0807    16.0925\n",
        "--------------------------------------------------------------------------------\n",
        "  toneXentropy  -117.6248    48.7763      -2.41     0.0173  -213.2264   -22.0233\n",
        "     intercept    25.5049    29.5837       0.86     0.3903   -32.4792    83.4890\n",
        "---------------------------------End of Summary---------------------------------"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# verify results with scikit-learn\n",
      "from sklearn.linear_model import LinearRegression\n",
      "y = grouped['mood'].as_matrix()\n",
      "X = grouped[['prev_mood', 'tone', 'stories', 'toneXstories', 'entropy', 'toneXentropy']].as_matrix()\n",
      "ols = LinearRegression()\n",
      "ols.fit(X=X, y=y)\n",
      "print ols.coef_\n",
      "print ols.intercept_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[  8.18203203e-01   2.93375254e+02  -9.91645111e-04   3.06217474e-02\n",
        "  -6.99411174e+00  -1.17624826e+02]\n",
        "25.5049005563\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# need event data\n",
      "pd.ols(y=grouped['mood'], x=grouped[['prev_mood', 'tone', 'stories', 'toneXstories', 'entropy', 'toneXentropy', 'event']])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# using high salience\n",
      "pd.ols(y=grouped['mood'], x=grouped[['prev_mood', 'tone', 'salient', 'toneXsalient', 'entropy', 'toneXentropy']])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "\n",
        "-------------------------Summary of Regression Analysis-------------------------\n",
        "\n",
        "Formula: Y ~ <prev_mood> + <tone> + <salient> + <toneXsalient> + <entropy>\n",
        "             + <toneXentropy> + <intercept>\n",
        "\n",
        "Number of Observations:         132\n",
        "Number of Degrees of Freedom:   7\n",
        "\n",
        "R-squared:         0.7697\n",
        "Adj R-squared:     0.7586\n",
        "\n",
        "Rmse:              3.7719\n",
        "\n",
        "F-stat (6, 125):    69.6126, p-value:     0.0000\n",
        "\n",
        "Degrees of Freedom: model 6, resid 125\n",
        "\n",
        "-----------------------Summary of Estimated Coefficients------------------------\n",
        "      Variable       Coef    Std Err     t-stat    p-value    CI 2.5%   CI 97.5%\n",
        "--------------------------------------------------------------------------------\n",
        "     prev_mood     0.8273     0.0529      15.64     0.0000     0.7236     0.9310\n",
        "          tone   222.0870   108.5272       2.05     0.0428     9.3737   434.8003\n",
        "       salient     0.3035     1.2607       0.24     0.8102    -2.1675     2.7744\n",
        "  toneXsalient     9.5688     5.0035       1.91     0.0581    -0.2380    19.3756\n",
        "       entropy   -10.0568    10.8627      -0.93     0.3563   -31.3477    11.2342\n",
        "--------------------------------------------------------------------------------\n",
        "  toneXentropy   -87.4134    43.5996      -2.00     0.0471  -172.8685    -1.9582\n",
        "     intercept    32.4802    27.6090       1.18     0.2417   -21.6334    86.5937\n",
        "---------------------------------End of Summary---------------------------------"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# need event data\n",
      "pd.ols(y=grouped['mood'], x=grouped[['prev_mood', 'tone', 'salient', 'toneXsalient', 'entropy', 'toneXentropy', 'event']])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    }
   ],
   "metadata": {}
  }
 ]
}